\section{Introduction}
\label{sec:introduction}

Due to the abundance of online text data, document summarization has become crucial
for efficiently and accurately extracting relevant information from a piece of text.
Over the past few years, Large Language Models (LLMs) have shown unique abilities for
many NLP tasks, including document summarization \cite{yadav2023state}.
Recent developments have demonstrated remarkable improvements in the relevancy of
summaries generated and the computational resources utilized by LLMs.

Even after the rapid growth of these models, one of the significant limitations of
LLMs is their context size, which disallows them from working on long documents.
Long document summarization is more crucial than ever since summarization involves
removing redundancies from a piece of text, which makes reading the text concise and
efficient.

This paper introduces several proposed algorithms that aim to handle long documents,
removing input size limitations in LLMs.

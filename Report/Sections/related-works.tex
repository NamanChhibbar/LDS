\section{Related Works}

In this section, we discuss some recent works related to long document summarization.


\subsection*{Summarization of Long Meeting Transcripts}

\citet{10.1145/3639233.3639253} describe a unique way of summarizing long meeting
transcripts.
Their approach is based on "Divide-and-Conquer", which starts with
segmenting the transcript to summarize each segment individually and combine them.
They use the BART (Bidirectional and Auto-Regressive Transformer) model for
summarization due to its high speed and performance.
They also extract action-item pairs to aid summarization.
After processing each segment, all summaries are combined for a final abstractive
summarization.
If the combined summarires fail to fit the context size, the combined summaries are
recursively segmented and summarized.
This study gives us insights into how we can process long inputs for summarization.


\subsection*{Question-Answering on Long Videos}

\citet{wang2024videoagent} introduce VideoAgent, an AI agent designed to answer a
given question using the context of a long video (approximately an hour long).
The agent first generates captions from multiple uniformly sampled frames from the
video, which are used to answer the question.
If the agent feels that the captions are not sufficient to answer the question, it
identifies a segment between the initial frames to obtain more frames.
This work is relevant since a long video, a sequence of frames, can be considered
analogous to a long document, a sequence of tokens. The techniques utilized by
VideoAgent can be adapted to perform query-based summarization in long documents.


\subsection*{Long Chinese News Classification}

\citet{chen2022long} describe a novel algorithm for long document classification
aimed to classify Chinese news into a set of pre-defined categories.
Their approach begins with pre-processing a long text by segmenting it into sentences
and forming groups of sentences determined by a fixed maximum number of tokens a
group should have.
BERT is then used to encode these groups of sentences for further processing.
Each sentence embedding is passed through a 1D convolution layer for local feature
extraction, followed by a 1D max-pooling layer.
Finally, a classifier head with softmax activation is used to classify using the
extracted features.
Methods utilized in this video, like segmenting and convolving, may prove helpful in
encoding long documents.

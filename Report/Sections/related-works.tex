\section{Related Works}

In this section, we discuss some recent works related to long document summarization.


\subsection*{Longformer}

\citet{beltagy2020longformer} introduce Longformer, a tranformer modified to handle
long sequences.
They do this by replacing the quadratic self attention mechanism in the transformer
architecture with a sliding window self attention, which has a linear complexity
with respect to input size.
To capture global dependencies, they add global attention to pre-selected input
positions.
They have also experimented with dilated sliding window and ablated models.


\subsection*{Summarization of Long Meeting Transcripts}

\citet{10.1145/3639233.3639253} describe a unique way of summarizing long meeting
transcripts.
Their approach is based on "Divide-and-Conquer", which starts with
segmenting the transcript to summarize each segment individually and combine them.
They use the BART (Bidirectional and Auto-Regressive Transformer) model to summarize
the segments due to its high speed and performance.
They also extract action-item pairs to aid summarization.
After processing every segment, all summaries are combined for a final abstractive
summarization.
If the combined summary fails to fit the context size, the combined summary is
recursively segmented and summarized again.
This study gives us insights into how we can process long inputs for summarization.


\subsection*{Question-Answering on Long Videos}

\citet{wang2024videoagent} introduce VideoAgent, an AI agent designed to answer a
given question using the context of a long video (approximately an hour long).
The agent first generates captions from multiple uniformly sampled frames from the
video, which are used to answer the question.
If the agent feels that the captions are not sufficient to answer the question, it
identifies a segment between the initial frames to obtain more frames.
This work is relevant since a long video, a sequence of frames, can be considered
analogous to a long document, a sequence of tokens. The techniques utilized by
VideoAgent can be adapted to perform query-based summarization in long documents.


\subsection*{Long Chinese News Classification}

\citet{chen2022long} describe a novel algorithm for long document classification
aimed to classify Chinese news into a set of pre-defined categories.
Their approach begins with pre-processing a long text by segmenting it into sentences
and forming groups of sentences determined by a fixed maximum number of tokens a
group should have.
BERT is then used to encode these groups of sentences for further processing.
Each sentence embedding is passed through a 1D convolution layer for local feature
extraction, followed by a 1D max-pooling layer.
Finally, a classifier head with softmax activation is used to classify using the
extracted features.
Methods utilized in this video, like segmenting and convolving, may prove helpful in
encoding long documents.

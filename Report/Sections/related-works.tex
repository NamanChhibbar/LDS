\section{Related Works}

\citet{golia2024action} take a "Divide and Conquer" based approach to address
sequence length limitations in summarizing long meeting transcripts.
They begin by segmenting the transcript and then use the BART (Bidirectional and
Auto-Regressive Transformer) model to summarize each segment individually.
These segment summaries are then recursively combined and summarized until a single
summary remains.
This method performs well with long documents but may take considerable amount of time
to converge due to repeated calls to the summarizer.

There have also been efforts to improve the efficiency of attention mechanisms in Transformers.
\citet{beltagy2020longformer} introduce Longformer, which replaces the quadratic
self-attention mechanism in the Transofrmer model with a sliding window self-attention,
resulting in a linear complexity with respect to the input size.
To capture long-ranged dependencies, they include global attention at specific token positions.
\citet{huang-etal-2021-efficient} modify the encoder-decoder attention mechanism such that
each attention head in the decoder attends to $n/s_h$ tokens in the input sequence, where
$n$ is input length and $s_h$ is number of heads.
This method has a complexity of $O(mn/s_h)$, where $m$ is the length of output sequence.
\citet{bertsch2023unlimiformer} introduce Unlimiformer, which also modifies the encoder-decoder
attention in a Transformer.
The attention heads in the decoder only attends to the tokens picked by their
k-nearest-neighbor (kNN) algorithm.
The kNN indices between the input tokens are created by the hidden states generated in the
encoder.
\citet{phang2022investigating} intorduce the staggered block-local attention mechanism.
In block-local attention mechanism, the input sequence is divided into non-overlapping blocks
and tokens in attend to tokens in the same block.
In staggered block-local attention, the blocks are staggered such that each token is in a
different block in each head.

Other unique approaches include VideoAgent, introduced by \citet{wang2024videoagent}, an
AI agent designed to answer a given question based on a long video.
They achieve this by generating captions from multiple uniformly sampled frames from the
video.
These captions are used to answer the user's question.
\citet{chen2022long} describe a novel algorithm to classify long Chinese news into a set
of predefined categories.
They form multiple groups of sentences based on maximum token threshold in each group.
These groups are then encoded using BERT (Bidirectional Encoder Representations from
Transformers) and passed through a 1D convolution layer for local feature extraction.
What makes this method special is that the attention mechanism is replaced by a 1D
convolution layer, which has linear complexity.

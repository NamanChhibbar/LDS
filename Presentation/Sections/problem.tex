\section{Problem Statement}

	\begin{frame}{The Problem}

		\begin{itemize}
			\item Transofrmers suffer from one major limitation: limited context size.
			\item This is due to the quadratic self-attention mechanism in the its architecture.
			\item For example, BART has a context size of just 1024 tokens (about 770 words).
			\item Due to this, transformers can not process long texts.
		\end{itemize}

	\end{frame}

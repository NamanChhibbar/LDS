{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import torch\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import inspect\n",
    "\n",
    "from pipelines import TruncateMiddle, UniformSampler\n",
    "from utils import *\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crs files: 7238, gao files: 12228\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/Users/naman/Workspace/Data/UCCS-REU\"\n",
    "\n",
    "crs_files = os.listdir(crs_dir := f\"{data_dir}/GovReport/crs\")\n",
    "gao_files = os.listdir(gao_dir := f\"{data_dir}/GovReport/gao\")\n",
    "\n",
    "print(f\"crs files: {len(crs_files)}, gao files: {len(gao_files)}\")\n",
    "\n",
    "crs_out = f\"{data_dir}/GovReport/crs-processed\"\n",
    "gao_out = f\"{data_dir}/GovReport/gao-processed\"\n",
    "\n",
    "preprocessor = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dir = f\"{data_dir}/Models/BART/tokenizer\"\n",
    "model_dir = f\"{data_dir}/Models/BART/model\"\n",
    "checkpoint = \"facebook/bart-large-cnn\"\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(tokenizer_dir)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_dir)\n",
    "\n",
    "context_size, _ = max_lengths(model)\n",
    "max_output_tokens = 500\n",
    "\n",
    "context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['<s>', '</s>', '<unk>', '</s>', '<pad>', '<s>', '<mask>'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens = tokenizer.special_tokens_map.values()\n",
    "postprocessor = TextPostprocessor(special_tokens)\n",
    "special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8357, 479)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = f\"{crs_out}/{crs_files[0]}\"\n",
    "\n",
    "with open(file) as fp:\n",
    "\tdata = json.load(fp)\n",
    "count_words(data[\"text\"]), count_words(data[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gov-report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in crs_files:\n",
    "\twith open(f\"{crs_dir}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\ttext = combine_subsections([data[\"reports\"]])\n",
    "\ttext = preprocessor.preprocess(text)\n",
    "\tsummary = \"\\n\".join(data[\"summary\"])\n",
    "\tsummary = preprocessor.preprocess(summary)\n",
    "\twith open(f\"{crs_out}/{file}\", \"w\") as fp:\n",
    "\t\tjson.dump({\n",
    "\t\t\t\"text\": text,\n",
    "\t\t\t\"summary\": summary\n",
    "\t\t}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "for file in gao_files:\n",
    "\twith open(f\"{gao_dir}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\ttext = combine_subsections(data[\"report\"])\n",
    "\ttext = preprocessor.preprocess(text)\n",
    "\tprint(data[\"highlight\"])\n",
    "\tsummary = \"\\n\".join(data[\"highlight\"])\n",
    "\tsummary = preprocessor.preprocess(summary)\n",
    "\twith open(f\"{gao_out}/{file}\", \"w\") as fp:\n",
    "\t\tjson.dump({\n",
    "\t\t\t\"text\": text,\n",
    "\t\t\t\"summary\": summary\n",
    "\t\t}, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_checkpoint = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "sent_save_dir = f\"{data_dir}/Models/Sent-Transformer\"\n",
    "\n",
    "sent_model = SentenceTransformer(sent_save_dir)\n",
    "sent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06765417, -0.03888808,  0.05449073, ...,  0.01187451,\n",
       "         0.04905998,  0.01324423],\n",
       "       [-0.11608477, -0.07559214,  0.05973152, ..., -0.01747406,\n",
       "        -0.00257643,  0.05474273],\n",
       "       [ 0.10994177, -0.04852243, -0.07865883, ...,  0.00304659,\n",
       "         0.0611313 , -0.02873247]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = sent_model.encode([\n",
    "\t\"hey bruh\",\n",
    "\t\"whats up huh?\",\n",
    "\tdata[\"text\"]\n",
    "])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Glass-Steagall Act separated commercial banking from investment banking. Separation of commercial and investment banking can help insulate insured depositories from volatility in securities markets. The separation, by itself, does not address how investment banks are regulated within securities markets or how nonbanks can use securities activities to fund consumer and commercial debt.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = TruncateMiddle(\n",
    "\tpreprocessor, postprocessor, tokenizer, model, context_size,\n",
    "\tmax_output_tokens, .4\n",
    ")\n",
    "\n",
    "summarizer(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The law was passed to prevent a repeat of the financial crisis of the 1930s and 1940s. The law was designed to prevent banks from taking on too much of a risk. It was also intended to prevent the creation of a financial system that was too risky for banks to take on.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = UniformSampler(\n",
    "\tpreprocessor, postprocessor, nltk.sent_tokenize, tokenizer, model,\n",
    "\tcontext_size, max_output_tokens\n",
    ")\n",
    "\n",
    "summarizer(data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uccs-reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

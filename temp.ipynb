{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "from time import sleep\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import inspect\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import (\n",
    "\tBartTokenizer, BartForConditionalGeneration,\n",
    "\tT5Tokenizer, T5ForConditionalGeneration,\n",
    "\tPegasusForConditionalGeneration, PegasusTokenizerFast,\n",
    "\tGPT2TokenizerFast\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.helpers import *\n",
    "from utils.encoders import *\n",
    "from utils.pipelines import *\n",
    "from utils.trainer_utils import *\n",
    "from utils.evaluator_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_histogram(data):\n",
    "\tbins = int(len(data) ** .5)\n",
    "\tplt.hist(data, bins=bins)\n",
    "\tplt.show()\n",
    "\n",
    "inf = float(\"inf\")\n",
    "filterwarnings(\"ignore\")\n",
    "device = get_device(500)\n",
    "# device = \"cpu\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7238, 2856)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/Users/naman/Workspace/Data/Long-Document-Summarization\"\n",
    "data_dir = \"/home/nchibbar/Data\"\n",
    "\n",
    "bart_dir = f\"{data_dir}/Models/BART\"\n",
    "t5_dir = f\"{data_dir}/Models/T5\"\n",
    "pegasus_dir = f\"{data_dir}/Models/PEGASUS\"\n",
    "gpt_dir = f\"{data_dir}/Models/GPT-3.5-turbo-tokenizer\"\n",
    "\n",
    "govreport_dir = f\"{data_dir}/GovReport/processed\"\n",
    "bigpatent_dir = f\"{data_dir}/BigPatent/processed\"\n",
    "govreport_files = os.listdir(govreport_dir)\n",
    "bigpatent_files = os.listdir(bigpatent_dir)\n",
    "\n",
    "len(govreport_files), len(bigpatent_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence transformer\n",
    "# Automatically loads into gpu if available\n",
    "sent_dir = f\"{data_dir}/Models/Sent-Transformer\"\n",
    "sent_encoder = SentenceTransformer(sent_dir)\n",
    "\n",
    "name = \"pegasus\"\n",
    "\n",
    "match name:\n",
    "\n",
    "\tcase \"bart\":\n",
    "\t\ttokenizer = BartTokenizer.from_pretrained(bart_dir)\n",
    "\t\tmodel = BartForConditionalGeneration.from_pretrained(bart_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"t5\":\n",
    "\t\ttokenizer = T5Tokenizer.from_pretrained(t5_dir)\n",
    "\t\tmodel = T5ForConditionalGeneration.from_pretrained(t5_dir)\n",
    "\t\tcontext_size = model.config.n_positions\n",
    "\n",
    "\tcase \"pegasus\":\n",
    "\t\ttokenizer = PegasusTokenizerFast.from_pretrained(pegasus_dir)\n",
    "\t\tmodel = PegasusForConditionalGeneration.from_pretrained(pegasus_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"gpt\":\n",
    "\t\ttokenizer = GPT2TokenizerFast.from_pretrained(gpt_dir)\n",
    "\t\tmodel = \"gpt-3.5-turbo\"\n",
    "\t\tcontext_size = 4096\n",
    "\n",
    "context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextProcessor(preprocessing=True)\n",
    "postprocessor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigPatent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for file in bigpatent_files:\n",
    "\tfile_path = f\"{bigpatent_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tfor text in data[\"texts\"]:\n",
    "\t\tword_counts.append(count_words(text))\n",
    "\n",
    "bins = int(len(word_counts) ** .5)\n",
    "plt.hist(word_counts, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(word_counts), min(word_counts), np.mean(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([\n",
    "\t1\n",
    "\tfor count in word_counts\n",
    "\tif count > 40_000\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_words = 20_000\n",
    "max_words = inf\n",
    "max_texts = inf\n",
    "texts, summaries = [], []\n",
    "num_texts = 0\n",
    "for file in govreport_files:\n",
    "\tfile_path = f\"{govreport_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tif min_words < count_words(data[\"text\"]) < max_words:\n",
    "\t\ttexts.append(data[\"text\"])\n",
    "\t\tsummaries.append(data[\"summary\"])\n",
    "\t\tnum_texts += 1\n",
    "\tif num_texts == max_texts:\n",
    "\t\tbreak\n",
    "\n",
    "num_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_min_words = 20\n",
    "text_segmenter = TextSegmenter(nltk.sent_tokenize, segment_min_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_preprocessor = TextProcessor(\n",
    "\tonly_words_nums = True,\n",
    "\tremove_nums = True\n",
    ")\n",
    "stop_words = get_stop_words(extra_stop_words=STOP_WORDS)\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tokens_frac = .5\n",
    "min_summary_tokens = 300\n",
    "head_size = .5\n",
    "threshold = .7\n",
    "boost = .03\n",
    "num_keywords = 20\n",
    "seed = 69\n",
    "system_prompt = \"You will be given some segments of a very long document. Your task is to summarize the entire document as a whole by extracting key information and ideas from the segments. Generate a detailed, concise, and coherent summary in 500 words. Do not refer to the document in the summary in any way.\"\n",
    "\n",
    "temperature = 2.\n",
    "repetition_penalty = 3.\n",
    "top_p = .95\n",
    "\n",
    "encoders = [\n",
    "\tTruncateMiddle(\n",
    "\t\ttokenizer, context_size, 1, preprocessor\n",
    "\t),\n",
    "\tTruncateMiddle(\n",
    "\t\ttokenizer, context_size, head_size, preprocessor, True\n",
    "\t),\n",
    "\tUniformSampler(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, preprocessor, True, seed\n",
    "\t),\n",
    "\tSegmentSampler(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, threshold, boost, seed\n",
    "\t),\n",
    "\tRemoveRedundancy(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, threshold, seed\n",
    "\t),\n",
    "\tKeywordScorer(\n",
    "\t\ttokenizer, context_size, text_segmenter, sent_encoder,\n",
    "\t\tpreprocessor, num_keywords, keywords_preprocessor, stop_words\n",
    "\t)\n",
    "]\n",
    "\n",
    "match name:\n",
    "\n",
    "\tcase \"gpt\":\n",
    "\t\tgpt_pipelines = [\n",
    "\t\t\tOpenAIPipeline(\n",
    "\t\t\t\tmodel, enc, system_prompt=system_prompt\n",
    "\t\t\t) for enc in encoders\n",
    "\t\t]\n",
    "\n",
    "\tcase _:\n",
    "\t\tpipelines = [\n",
    "\t\t\tSummarizationPipeline(\n",
    "\t\t\t\tmodel, enc, postprocessor, min_summary_tokens,\n",
    "\t\t\t\tcontext_size, device, temperature, repetition_penalty, top_p\n",
    "\t\t\t) for enc in encoders\n",
    "\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = preprocessor(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_segments = []\n",
    "avg_segment = 0\n",
    "total_segments = 0\n",
    "for text in processed_texts:\n",
    "\tsegments = text_segmenter(text)\n",
    "\tfor segment in segments:\n",
    "\t\tavg_segment += count_words(segment)\n",
    "\t\ttotal_segments += 1\n",
    "\tmax_word_segments.append(\n",
    "\t\tmax(segments, key=lambda segment: count_words(segment))\n",
    "\t)\n",
    "avg_segment /= total_segments\n",
    "avg_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearable_words = 150\n",
    "for i, segment in enumerate(max_word_segments):\n",
    "\twords = count_words(segment)\n",
    "\tif words > bearable_words:\n",
    "\t\tprint(\n",
    "\t\t\tf\"{i} {words}: {repr(segment)}\",\n",
    "\t\t\tend = \"\\n\\n\"\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 7143\n",
    "print(\n",
    "\tprocessed_texts[ind], texts[ind],\n",
    "\tsep = f\"\\n\\n{\"=\" * 400}\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65193915, 0.6542208 , 0.65794206, 0.69529766, 0.6995131 ,\n",
       "       0.70691174, 0.7073892 , 0.7171764 , 0.7178343 , 0.71939534,\n",
       "       0.7217039 , 0.72373635, 0.7324604 , 0.73268557, 0.73460007,\n",
       "       0.73581743, 0.7372252 , 0.7412356 , 0.7424157 , 0.7426511 ,\n",
       "       0.74519473, 0.745373  , 0.7456744 , 0.74736893, 0.749151  ,\n",
       "       0.74943566, 0.75022244, 0.752278  , 0.75245076, 0.75440687,\n",
       "       0.75562906, 0.7567007 , 0.75692   , 0.7570452 , 0.7581953 ,\n",
       "       0.7583513 , 0.7586851 , 0.758883  , 0.7592064 , 0.7594475 ,\n",
       "       0.75984323, 0.76003677, 0.7606733 , 0.7612004 , 0.7618613 ,\n",
       "       0.76232195, 0.7631042 , 0.763729  , 0.76401484, 0.76408005,\n",
       "       0.7642471 , 0.7642544 , 0.76503026, 0.7651434 , 0.7661807 ,\n",
       "       0.766662  , 0.76669765, 0.76683724, 0.76692486, 0.76692766,\n",
       "       0.76713556, 0.7672833 , 0.7674605 , 0.7674811 , 0.767522  ,\n",
       "       0.7676269 , 0.7679292 , 0.76831627, 0.76873004, 0.76901287,\n",
       "       0.7690211 , 0.7691008 , 0.7695514 , 0.76964384, 0.76975906,\n",
       "       0.7698481 , 0.7699915 , 0.7703122 , 0.7704705 , 0.7708157 ,\n",
       "       0.77092725, 0.7710595 , 0.7712507 , 0.7713654 , 0.7713783 ,\n",
       "       0.7716538 , 0.7719693 , 0.7722188 , 0.77230453, 0.77269864,\n",
       "       0.7728381 , 0.77289426, 0.77301663, 0.7734643 , 0.77361965,\n",
       "       0.7737033 , 0.7738805 , 0.77413106, 0.7745375 , 0.7746972 ,\n",
       "       0.7748203 , 0.7749658 , 0.7750148 , 0.7750687 , 0.77532744,\n",
       "       0.7757224 , 0.77606106, 0.7762499 , 0.77649933, 0.7765583 ,\n",
       "       0.77659494, 0.7769224 , 0.77692527, 0.7774638 , 0.7788607 ,\n",
       "       0.7788904 , 0.77926344, 0.77949584, 0.7795528 , 0.7795688 ,\n",
       "       0.77987957, 0.7800297 , 0.78024876, 0.78026795, 0.78051317,\n",
       "       0.7806312 , 0.78063816, 0.78146994, 0.7814908 , 0.78155375,\n",
       "       0.7816006 , 0.78187686, 0.781883  , 0.78207856, 0.78222466,\n",
       "       0.7822293 , 0.78224164, 0.7822969 , 0.7823394 , 0.78237724,\n",
       "       0.78272444, 0.7827859 , 0.7828588 , 0.7830639 , 0.7833102 ,\n",
       "       0.7833859 , 0.7836762 , 0.7837339 , 0.7837465 , 0.7837812 ,\n",
       "       0.78379476, 0.7843667 , 0.7844082 , 0.78442633, 0.784442  ,\n",
       "       0.7847491 , 0.7848953 , 0.7849686 , 0.7850319 , 0.7851063 ,\n",
       "       0.7851981 , 0.785295  , 0.78538   , 0.7853906 , 0.78551257,\n",
       "       0.7855542 , 0.78559464, 0.785614  , 0.785617  , 0.7856273 ,\n",
       "       0.7859028 , 0.78609186, 0.7865026 , 0.7865169 , 0.78656757,\n",
       "       0.7868806 , 0.7870929 , 0.78725386, 0.7872689 , 0.78729755,\n",
       "       0.7873793 , 0.7874591 , 0.7875922 , 0.78773224, 0.78788793,\n",
       "       0.7879921 , 0.7882497 , 0.7884314 , 0.7890729 , 0.7891375 ,\n",
       "       0.78921366, 0.78928876, 0.78932333, 0.78947663, 0.7895445 ,\n",
       "       0.78997624, 0.78998244, 0.7900141 , 0.7900287 , 0.79011846,\n",
       "       0.79024464, 0.7903913 , 0.7904423 , 0.7905703 , 0.7906437 ,\n",
       "       0.7908547 , 0.7909321 , 0.79095113, 0.79097295, 0.79106355,\n",
       "       0.7913109 , 0.7914267 , 0.7914679 , 0.7916936 , 0.7917683 ,\n",
       "       0.7917702 , 0.791793  , 0.79194975, 0.7920263 , 0.792043  ,\n",
       "       0.7921502 , 0.79231715, 0.79264927, 0.7928416 , 0.7929176 ,\n",
       "       0.7933057 , 0.79347444, 0.79351884, 0.7935287 , 0.79353   ,\n",
       "       0.7935449 , 0.7935691 , 0.7935875 , 0.793592  , 0.7935921 ,\n",
       "       0.79362434, 0.79373777, 0.7938615 , 0.7939607 , 0.7939757 ,\n",
       "       0.7940791 , 0.79414207, 0.7942509 , 0.7948717 , 0.7950142 ,\n",
       "       0.79510736, 0.7951271 , 0.79513663, 0.7952725 , 0.7955022 ,\n",
       "       0.79557246, 0.79612136, 0.7963204 , 0.79632276, 0.79660726,\n",
       "       0.79665786, 0.796732  , 0.7968514 , 0.7974604 , 0.7978562 ,\n",
       "       0.79802173, 0.7985412 , 0.79855204, 0.7988316 , 0.799518  ,\n",
       "       0.79993176, 0.8001678 , 0.80017763, 0.8002007 , 0.800367  ,\n",
       "       0.8005576 , 0.80075824, 0.80110747, 0.8012798 , 0.80147874,\n",
       "       0.8020009 , 0.8020791 , 0.80226225, 0.8026236 , 0.80277514,\n",
       "       0.80327964, 0.8033329 , 0.8044482 , 0.8047144 , 0.8051996 ,\n",
       "       0.80520785, 0.80521107, 0.8053678 , 0.805478  , 0.8057701 ,\n",
       "       0.80579257, 0.806236  , 0.8066058 , 0.8071784 , 0.8076215 ,\n",
       "       0.8086876 , 0.8087614 , 0.8089293 , 0.80910504, 0.80931175,\n",
       "       0.80946934, 0.8098419 , 0.81143785, 0.81162375, 0.8119452 ,\n",
       "       0.81292844, 0.81619126, 0.81694865, 0.8197614 , 0.8241391 ,\n",
       "       0.8313296 , 0.8326931 , 0.8354887 , 0.8356948 , 0.8381845 ,\n",
       "       0.84506434, 0.8508445 ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{data_dir}/pegasus-govreport.pkl\", \"rb\") as fp:\n",
    "\tresults = pickle.load(fp)\n",
    "scores = results[\"scores\"]\n",
    "sort1, sort2, sort3 = results[\"sort1\"], results[\"sort2\"], results[\"sort3\"]\n",
    "gen_summaries = results[\"gen_summaries\"]\n",
    "scores[0][sort1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elections are widely considered a key harbinger of the durability and extent of Afghanistan's political development and a barometer for measuring the effects of factional, political, ethnic, and sectarian rivalries. The 2009 presidential and provincial elections were the first post-Taliban elections run by the Afghan government through its Afghanistan Independent Electoral Commission (IEC) DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch DropCatch\n"
     ]
    }
   ],
   "source": [
    "problem_text = results[\"texts\"][sort1[0]]\n",
    "print(gen_summaries[sort1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoders[-1](problem_text, return_batch=False)\n",
    "sent = tokenizer.decode(enc, skip_special_tokens=True)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_problem = preprocessor(problem_text)\n",
    "segments = text_segmenter(processed_problem)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"As a judge on the United States Court of Appeals for the Second Circuit, Justice Sotomayor has had an opportunity to write opinions that have implications in areas such as gun control, civil rights, search and seizure, habeas corpus, and post-conviction relief. In contrast to the cases described above, Judge Sotomayor has also authored several civil rights opinions in which she ruled or would have ruled against the party claiming discrimination. This report selected cases authored by Judge Sotomayor during her tenure on the Second Circuit, including majority, concurring, and dissenting opinions in areas of legal significance.This report selected cases authored by Judge Sotomayor during her tenure on the Second Circuit, including majority, concurring, and dissenting opinions in areas of legal significance. this report selected cases authored by Judge Sotomayor during her tenure on the Second Circuit, including majority, concurring, and dissenting opinions in areas of legal significance.this report selected cases authored by Judge Sotomayor during her tenure on the Second Circuit, including majority, concurring, and dissenting opinions in areas of legal significance.these reports are based on data gathered from the US Court of Appeals for the Second Circuit's website (www.SecondCircuit.com) and do not necessarily reflect the views of the Supreme Court. these reports are based on data gathered from the US Court of Appeals for the Second Circuit's website (www.SecondCircuit.com) and do not necessarily reflect the views of the Supreme Court. These reports are based on data gathered from the US Court's website ( www.SecondCircuit.\"]\n"
     ]
    }
   ],
   "source": [
    "print(pipelines[-1](problem_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In May 2009, Supreme Court Justice David Souter announced his intention to retire from the Supreme Court. Several weeks later, President Obama nominated Judge Sonia Sotomayor, who served on the U.S. Court of Appeals for the Second Circuit, to fill his seat. To fulfill its constitutional \"advice and consent\" function, the Senate considered Judge Sotomayor's extensive record—compiled from years as a lawyer, prosecutor, district court judge, and appellate court judge—to better understand her legal approaches and judicial philosophy. On August 6, the Senate confirmed Justice Sotomayor by a vote of 68-31, and she was sworn in on August 8. This report provides an analysis of selected opinions authored by Judge Sotomayor during her tenure as a judge on the Second Circuit. Discussions of the selected opinions are grouped according to various topics of legal significance. As a group, the opinions belie easy categorization along any ideological spectrum. However, it is possible to draw some conclusions regarding Judge Sotomayor's judicial approach, both within some specific issue areas and in general. Perhaps the most consistent characteristic of Judge Sotomayor's approach as an appellate judge has been an adherence to the doctrine of stare decisis (i.e., the upholding of past judicial precedents). Other characteristics appear to include what many would describe as a careful application of particular facts at issue in a case and a dislike for situations in which the court might be seen as overstepping its judicial role. It is difficult to determine the extent to which Judge Sotomayor's style as a judge on the Second Circuit will predict her style as a Supreme Court justice. However, as has been the case historically with other nominees, some of her approaches may be enduring characteristics.\n"
     ]
    }
   ],
   "source": [
    "print(results[\"summaries\"][sort1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uccs-reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

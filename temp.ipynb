{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "from time import sleep\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import inspect\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import (\n",
    "\tBartTokenizer, BartForConditionalGeneration,\n",
    "\tT5Tokenizer, T5ForConditionalGeneration,\n",
    "\tPegasusForConditionalGeneration, PegasusTokenizerFast,\n",
    "\tGPT2TokenizerFast\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.helpers import *\n",
    "from utils.encoders import *\n",
    "from utils.pipelines import *\n",
    "from utils.trainer_utils import *\n",
    "from utils.evaluator_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_histogram(data):\n",
    "\tbins = int(len(data) ** .5)\n",
    "\tplt.hist(data, bins=bins)\n",
    "\tplt.show()\n",
    "\n",
    "inf = float(\"inf\")\n",
    "filterwarnings(\"ignore\")\n",
    "device = get_device(500)\n",
    "# device = \"cpu\"\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7238, 2856)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/Users/naman/Workspace/Data/Long-Document-Summarization\"\n",
    "data_dir = \"/home/nchibbar/Data\"\n",
    "\n",
    "bart_dir = f\"{data_dir}/Models/BART\"\n",
    "t5_dir = f\"{data_dir}/Models/T5\"\n",
    "pegasus_dir = f\"{data_dir}/Models/PEGASUS\"\n",
    "gpt_dir = f\"{data_dir}/Models/GPT-3.5-turbo-tokenizer\"\n",
    "\n",
    "govreport_dir = f\"{data_dir}/GovReport/processed\"\n",
    "bigpatent_dir = f\"{data_dir}/BigPatent/processed\"\n",
    "govreport_files = os.listdir(govreport_dir)\n",
    "bigpatent_files = os.listdir(bigpatent_dir)\n",
    "\n",
    "len(govreport_files), len(bigpatent_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence transformer\n",
    "# Automatically loads into gpu if available\n",
    "sent_dir = f\"{data_dir}/Models/Sent-Transformer\"\n",
    "sent_encoder = SentenceTransformer(sent_dir)\n",
    "\n",
    "name = \"pegasus\"\n",
    "\n",
    "match name:\n",
    "\n",
    "\tcase \"bart\":\n",
    "\t\ttokenizer = BartTokenizer.from_pretrained(bart_dir)\n",
    "\t\tmodel = BartForConditionalGeneration.from_pretrained(bart_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"t5\":\n",
    "\t\ttokenizer = T5Tokenizer.from_pretrained(t5_dir)\n",
    "\t\tmodel = T5ForConditionalGeneration.from_pretrained(t5_dir)\n",
    "\t\tcontext_size = model.config.n_positions\n",
    "\n",
    "\tcase \"pegasus\":\n",
    "\t\ttokenizer = PegasusTokenizerFast.from_pretrained(pegasus_dir)\n",
    "\t\tmodel = PegasusForConditionalGeneration.from_pretrained(pegasus_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"gpt\":\n",
    "\t\ttokenizer = GPT2TokenizerFast.from_pretrained(gpt_dir)\n",
    "\t\tmodel = \"gpt-3.5-turbo\"\n",
    "\t\tcontext_size = 4096\n",
    "\n",
    "context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextProcessor(preprocessing=True)\n",
    "postprocessor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigPatent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for file in bigpatent_files:\n",
    "\tfile_path = f\"{bigpatent_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tfor text in data[\"texts\"]:\n",
    "\t\tword_counts.append(count_words(text))\n",
    "\n",
    "bins = int(len(word_counts) ** .5)\n",
    "plt.hist(word_counts, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(word_counts), min(word_counts), np.mean(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([\n",
    "\t1\n",
    "\tfor count in word_counts\n",
    "\tif count > 40_000\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_words = 20_000\n",
    "max_words = inf\n",
    "max_texts = inf\n",
    "texts, summaries = [], []\n",
    "num_texts = 0\n",
    "for file in govreport_files:\n",
    "\tfile_path = f\"{govreport_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tif min_words < count_words(data[\"text\"]) < max_words:\n",
    "\t\ttexts.append(data[\"text\"])\n",
    "\t\tsummaries.append(data[\"summary\"])\n",
    "\t\tnum_texts += 1\n",
    "\tif num_texts == max_texts:\n",
    "\t\tbreak\n",
    "\n",
    "num_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_min_words = 20\n",
    "text_segmenter = TextSegmenter(nltk.sent_tokenize, segment_min_words)\n",
    "keywords_preprocessor = TextProcessor(\n",
    "\tonly_words_nums = True,\n",
    "\tremove_nums = True\n",
    ")\n",
    "stop_words = get_stop_words(extra_stop_words=STOP_WORDS)\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_tokens_frac = .5\n",
    "min_summary_tokens = 300\n",
    "head_size = .5\n",
    "threshold = .7\n",
    "boost = .03\n",
    "num_keywords = 20\n",
    "seed = 69\n",
    "system_prompt = \"You will be given some segments of a very long document. Your task is to summarize the entire document as a whole by extracting key information and ideas from the segments. Generate a detailed, concise, and coherent summary in 500 words. Do not refer to the document in the summary in any way.\"\n",
    "\n",
    "temperature = 2.\n",
    "repetition_penalty = 3.\n",
    "top_p = .95\n",
    "\n",
    "encoders = [\n",
    "\tTruncateMiddle(\n",
    "\t\ttokenizer, context_size, 1, preprocessor\n",
    "\t),\n",
    "\tTruncateMiddle(\n",
    "\t\ttokenizer, context_size, head_size, preprocessor, True\n",
    "\t),\n",
    "\tUniformSampler(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, preprocessor, True, seed\n",
    "\t),\n",
    "\tSegmentSampler(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, threshold, boost, seed\n",
    "\t),\n",
    "\tRemoveRedundancy(\n",
    "\t\ttokenizer, min_tokens_frac * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, threshold, seed\n",
    "\t),\n",
    "\tKeywordScorer(\n",
    "\t\ttokenizer, context_size, text_segmenter, sent_encoder,\n",
    "\t\tpreprocessor, num_keywords, keywords_preprocessor, stop_words\n",
    "\t)\n",
    "]\n",
    "\n",
    "match name:\n",
    "\n",
    "\tcase \"gpt\":\n",
    "\t\tgpt_pipelines = [\n",
    "\t\t\tOpenAIPipeline(\n",
    "\t\t\t\tmodel, enc, system_prompt=system_prompt\n",
    "\t\t\t) for enc in encoders\n",
    "\t\t]\n",
    "\n",
    "\tcase _:\n",
    "\t\tpipelines = [\n",
    "\t\t\tSummarizationPipeline(\n",
    "\t\t\t\tmodel, enc, postprocessor, min_summary_tokens,\n",
    "\t\t\t\tcontext_size, device, temperature, repetition_penalty, top_p\n",
    "\t\t\t) for enc in encoders\n",
    "\t\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = preprocessor(texts)\n",
    "max_word_segments = []\n",
    "avg_segment = 0\n",
    "total_segments = 0\n",
    "for text in processed_texts:\n",
    "\tsegments = text_segmenter(text)\n",
    "\tfor segment in segments:\n",
    "\t\tavg_segment += count_words(segment)\n",
    "\t\ttotal_segments += 1\n",
    "\tmax_word_segments.append(\n",
    "\t\tmax(segments, key=lambda segment: count_words(segment))\n",
    "\t)\n",
    "avg_segment /= total_segments\n",
    "avg_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bearable_words = 150\n",
    "for i, segment in enumerate(max_word_segments):\n",
    "\twords = count_words(segment)\n",
    "\tif words > bearable_words:\n",
    "\t\tprint(\n",
    "\t\t\tf\"{i} {words}: {repr(segment)}\",\n",
    "\t\t\tend = \"\\n\\n\"\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 7143\n",
    "print(\n",
    "\tprocessed_texts[ind], texts[ind],\n",
    "\tsep = f\"\\n\\n{\"=\" * 400}\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.675691  , 0.7162112 , 0.7574562 , 0.75933695, 0.76402986,\n",
       "       0.7669531 , 0.767002  , 0.7677376 , 0.76811725, 0.7697828 ,\n",
       "       0.77050906, 0.7721592 , 0.7731201 , 0.7739637 , 0.7757685 ,\n",
       "       0.7759561 , 0.7759706 , 0.7761142 , 0.7779481 , 0.78167456,\n",
       "       0.7828735 , 0.78393763, 0.784287  , 0.78458005, 0.78500414,\n",
       "       0.78527856, 0.78571516, 0.78596365, 0.7860271 , 0.7860367 ,\n",
       "       0.7872863 , 0.7875255 , 0.7876092 , 0.7876619 , 0.7879738 ,\n",
       "       0.78806406, 0.7882248 , 0.7882396 , 0.7885411 , 0.7886226 ,\n",
       "       0.78864753, 0.7886622 , 0.7890073 , 0.78908485, 0.78910667,\n",
       "       0.78911954, 0.78919554, 0.7891998 , 0.7892448 , 0.78964186,\n",
       "       0.78969586, 0.78992486, 0.79017186, 0.7904004 , 0.79045725,\n",
       "       0.79065657, 0.7906741 , 0.79072493, 0.7908622 , 0.79091513,\n",
       "       0.7913277 , 0.79158986, 0.79188424, 0.79211515, 0.79226184,\n",
       "       0.79251784, 0.7925694 , 0.79282624, 0.79307777, 0.79335654,\n",
       "       0.79359376, 0.7937025 , 0.7937305 , 0.79377246, 0.79380244,\n",
       "       0.79390275, 0.794238  , 0.7944541 , 0.7949066 , 0.7949295 ,\n",
       "       0.79502904, 0.79508305, 0.79543614, 0.7955118 , 0.7957051 ,\n",
       "       0.79583275, 0.79595965, 0.7961566 , 0.796232  , 0.7963588 ,\n",
       "       0.7965925 , 0.79662466, 0.79665625, 0.79671866, 0.79672694,\n",
       "       0.7972323 , 0.79723567, 0.79756546, 0.79759324, 0.7975978 ,\n",
       "       0.79767084, 0.79769576, 0.7976983 , 0.797733  , 0.79810786,\n",
       "       0.7981775 , 0.79838955, 0.7985012 , 0.7986355 , 0.7986738 ,\n",
       "       0.79867923, 0.7989656 , 0.7989992 , 0.79927075, 0.7994422 ,\n",
       "       0.7996037 , 0.79982865, 0.79987967, 0.79988134, 0.8000347 ,\n",
       "       0.8001601 , 0.80032563, 0.8004265 , 0.8004642 , 0.8005024 ,\n",
       "       0.8005568 , 0.80061257, 0.80072355, 0.80081666, 0.8008248 ,\n",
       "       0.80113244, 0.801182  , 0.8012068 , 0.80123305, 0.80128175,\n",
       "       0.80135465, 0.8014183 , 0.8014582 , 0.8016993 , 0.80178607,\n",
       "       0.8019568 , 0.8019684 , 0.80197805, 0.8021193 , 0.8021295 ,\n",
       "       0.8024869 , 0.8025019 , 0.802578  , 0.802584  , 0.802621  ,\n",
       "       0.8027431 , 0.8028235 , 0.80286276, 0.80306727, 0.80310297,\n",
       "       0.8031158 , 0.8031763 , 0.80335236, 0.80362284, 0.80364406,\n",
       "       0.80366254, 0.80378926, 0.8039746 , 0.8040488 , 0.80414516,\n",
       "       0.80418086, 0.8042012 , 0.8043759 , 0.80471724, 0.8047193 ,\n",
       "       0.8047706 , 0.8048396 , 0.80515295, 0.80553734, 0.80576515,\n",
       "       0.8057791 , 0.80597794, 0.80601984, 0.8060781 , 0.8062166 ,\n",
       "       0.80628103, 0.80629313, 0.80636835, 0.8065149 , 0.8066088 ,\n",
       "       0.806696  , 0.8066997 , 0.8067123 , 0.8067264 , 0.8068708 ,\n",
       "       0.8069178 , 0.8069852 , 0.80702937, 0.80726224, 0.80727077,\n",
       "       0.8074674 , 0.80779433, 0.80784947, 0.80793524, 0.80808413,\n",
       "       0.80818737, 0.8082673 , 0.8082762 , 0.8087922 , 0.8089225 ,\n",
       "       0.8089643 , 0.8093256 , 0.80940455, 0.80962133, 0.80975926,\n",
       "       0.8099241 , 0.80999494, 0.8101955 , 0.8102539 , 0.81030905,\n",
       "       0.81038874, 0.8105109 , 0.8109658 , 0.81103224, 0.8110709 ,\n",
       "       0.81115925, 0.81126964, 0.8114319 , 0.81151223, 0.81168056,\n",
       "       0.81176317, 0.8119847 , 0.812135  , 0.8122503 , 0.81242174,\n",
       "       0.8124714 , 0.8125481 , 0.8126055 , 0.81278706, 0.8130611 ,\n",
       "       0.81346   , 0.8134626 , 0.81389946, 0.8141295 , 0.81426775,\n",
       "       0.814311  , 0.81431687, 0.8143296 , 0.81447333, 0.81473356,\n",
       "       0.814749  , 0.8148724 , 0.81513494, 0.81515527, 0.8153497 ,\n",
       "       0.8153934 , 0.81560314, 0.81588054, 0.8158913 , 0.8159331 ,\n",
       "       0.81627715, 0.8164234 , 0.8165873 , 0.8168076 , 0.81699044,\n",
       "       0.81721747, 0.81743896, 0.81781197, 0.8178867 , 0.8181528 ,\n",
       "       0.8185267 , 0.8185469 , 0.8191842 , 0.8195747 , 0.8196118 ,\n",
       "       0.81997633, 0.819996  , 0.8201367 , 0.82020974, 0.82113504,\n",
       "       0.8211595 , 0.821738  , 0.82231677, 0.8223941 , 0.82245994,\n",
       "       0.8227625 , 0.82345057, 0.82352227, 0.8238536 , 0.82423496,\n",
       "       0.8243028 , 0.82478106, 0.8249725 , 0.8252969 , 0.8253796 ,\n",
       "       0.82541394, 0.82565737, 0.8257825 , 0.827584  , 0.8277928 ,\n",
       "       0.8282068 , 0.8300005 , 0.8306902 , 0.83152986, 0.8320159 ,\n",
       "       0.8328265 , 0.8328606 , 0.8334459 , 0.8348002 , 0.83522475,\n",
       "       0.83594596, 0.8371502 , 0.8379437 , 0.8431942 , 0.84339833,\n",
       "       0.8506944 , 0.8515617 , 0.85224193, 0.85268795, 0.8528747 ,\n",
       "       0.86847806, 0.87271976], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{data_dir}/pegasus-govreport.pkl\", \"rb\") as fp:\n",
    "\tresults = pickle.load(fp)\n",
    "scores = results[\"scores\"]\n",
    "sort1, sort2, sort3 = results[\"sort1\"], results[\"sort2\"], results[\"sort3\"]\n",
    "gen_summaries = results[\"gen_summaries\"]\n",
    "scores[0][sort1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A glossary of terms: Aid to Families with Dependent Children (AFDC): Subsection Basic Eligibility: permits a state to give basic cash1-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-65561-6556\n"
     ]
    }
   ],
   "source": [
    "problem_text = results[\"texts\"][sort1[0]]\n",
    "print(gen_summaries[sort1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The FBI and the FSB, Russia's Federal Security Service (FSB), have been working together on counter-terrorism issues for several years, according to a senior Obama Administration official who spoke on the condition of anonymity because he was not allowed to speak publicly about the matter. A senior Obama Administration official commented that missile defense \"has never been about Russia.\" Former U.S Ambassador to Russia Michael McFaul stated that, in response to the Ukraine/Crimea crisis, the United States should cease cooperation with Russia on a number of fronts, including negotiations over joint missile defensive systems under the auspices of the NATO-Russia Council - but only if Moscow accepts the alliance's new European missile shield plans as part of its agreement to withdraw from the 1987 Intermediate-range Nuclear Forces Treaty (INF treaty) - which expires at the end of this year.A senior Obama Administration official commented that, in response to the Ukraine/Crimea crisis, the United States should cease cooperation with Russia on a number of fronts, including negotiations over joint missile Defense systems under the auspices of the NATO-Russia Council - but only if Moscow accepts the alliance's new European missile shield plans as part of its agreement to withdraw from the INF treaty - which expires at the end of this year.Former U.S Ambassador to Russia Michael McFaul stated that, in response to the Ukraine/Crimea crisis, the United States should cease cooperation with Russia on a number of fronts, including negotiations over joint missile defence systems under the auspices of the NATO-Russia Council.\n"
     ]
    }
   ],
   "source": [
    "print(pipelines[-1](problem_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoders[-1](problem_text, return_batch=False)\n",
    "sent = tokenizer.decode(enc, skip_special_tokens=True)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_problem = preprocessor(problem_text)\n",
    "segments = text_segmenter(processed_problem)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipelines[-1](problem_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[\"summaries\"][sort1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uccs-reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

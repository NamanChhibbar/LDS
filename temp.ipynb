{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import inspect\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers as tfm\n",
    "import sentence_transformers as stfm\n",
    "import dotenv\n",
    "\n",
    "import configs as c\n",
    "import encoders as e\n",
    "import pipelines as p\n",
    "import utils as u\n",
    "\n",
    "def plot_histogram(data):\n",
    "\tbins = int(len(data) ** .5)\n",
    "\tplt.hist(data, bins=bins)\n",
    "\tplt.show()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = u.get_device(c.GPU_USAGE_TOLERANCE)\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pegasus\"\n",
    "\n",
    "sent_dir = f\"{c.MODELS_DIR}/sent-transformer\"\n",
    "model_dir = f\"{c.MODELS_DIR}/{model_name.lower()}\"\n",
    "\n",
    "govreport_dir = f\"{c.BASE_DIR}/GovReport/processed\"\n",
    "bigpatent_dir = f\"{c.BASE_DIR}/BigPatent/processed\"\n",
    "govreport_files = os.listdir(govreport_dir)\n",
    "bigpatent_files = os.listdir(bigpatent_dir)\n",
    "\n",
    "len(govreport_files), len(bigpatent_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence transformer\n",
    "# Automatically loads into gpu if available\n",
    "sent_encoder = stfm.SentenceTransformer(sent_dir, device=device)\n",
    "\n",
    "match model_name:\n",
    "\n",
    "\tcase \"bart\":\n",
    "\t\ttokenizer = tfm.BartTokenizer.from_pretrained(model_dir)\n",
    "\t\tmodel = tfm.BartForConditionalGeneration.from_pretrained(model_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"t5\":\n",
    "\t\ttokenizer = tfm.T5Tokenizer.from_pretrained(model_dir)\n",
    "\t\tmodel = tfm.T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "\t\tcontext_size = model.config.n_positions\n",
    "\n",
    "\tcase \"pegasus\":\n",
    "\t\ttokenizer = tfm.PegasusTokenizerFast.from_pretrained(model_dir)\n",
    "\t\tmodel = tfm.PegasusForConditionalGeneration.from_pretrained(model_dir)\n",
    "\t\tcontext_size = model.config.max_position_embeddings\n",
    "\n",
    "\tcase \"gpt\":\n",
    "\t\ttokenizer = tfm.GPT2TokenizerFast.from_pretrained(model_dir)\n",
    "\t\tmodel = \"gpt-3.5-turbo\"\n",
    "\t\tcontext_size = 4096\n",
    "\n",
    "context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = u.TextProcessor(preprocessing=True)\n",
    "postprocessor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigPatent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for file in bigpatent_files:\n",
    "\tfile_path = f\"{bigpatent_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tfor text in data[\"texts\"]:\n",
    "\t\tword_counts.append(u.count_words(text))\n",
    "\n",
    "plot_histogram(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(word_counts), np.mean(word_counts), len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([\n",
    "\t1\n",
    "\tfor count in word_counts\n",
    "\tif count > 40_000\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, summaries = [], []\n",
    "num_texts = 0\n",
    "for file in govreport_files:\n",
    "\tfile_path = f\"{govreport_dir}/{file}\"\n",
    "\twith open(file_path) as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tif c.MIN_WORDS < u.count_words(data[\"text\"]) < c.MAX_WORDS:\n",
    "\t\ttexts.append(data[\"text\"])\n",
    "\t\tsummaries.append(data[\"summary\"])\n",
    "\t\tnum_texts += 1\n",
    "\tif num_texts == c.MAX_TEXTS:\n",
    "\t\tbreak\n",
    "\n",
    "num_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_MIN_WORDS = 20\n",
    "text_segmenter = u.TextSegmenter(nltk.sent_tokenize, SEGMENT_MIN_WORDS)\n",
    "keywords_preprocessor = u.TextProcessor(\n",
    "\tonly_words_nums = True,\n",
    "\tremove_nums = True\n",
    ")\n",
    "stop_words = u.get_stop_words(extra_stop_words=c.EXTRA_STOP_WORDS)\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [\n",
    "\te.TruncateMiddle(\n",
    "\t\ttokenizer, context_size, 1, preprocessor\n",
    "\t),\n",
    "\te.TruncateMiddle(\n",
    "\t\ttokenizer, context_size, c.HEAD_SIZE, preprocessor, True\n",
    "\t),\n",
    "\te.UniformSampler(\n",
    "\t\ttokenizer, c.MIN_TOKEN_FRAC * context_size, context_size,\n",
    "\t\ttext_segmenter, preprocessor, True, c.SEED\n",
    "\t),\n",
    "\te.SegmentSampler(\n",
    "\t\ttokenizer, c.MIN_TOKEN_FRAC * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, c.THRESHOLD, c.PROB_BOOST, c.SEED\n",
    "\t),\n",
    "\te.RemoveRedundancy(\n",
    "\t\ttokenizer, c.MIN_TOKEN_FRAC * context_size, context_size,\n",
    "\t\ttext_segmenter, sent_encoder, preprocessor, c.THRESHOLD, c.SEED\n",
    "\t),\n",
    "\te.KeywordScorer(\n",
    "\t\ttokenizer, context_size, text_segmenter, sent_encoder,\n",
    "\t\tpreprocessor, c.NUM_KEYWORDS, keywords_preprocessor, stop_words\n",
    "\t)\n",
    "]\n",
    "\n",
    "pipelines = [\n",
    "\tp.SummarizationPipeline(\n",
    "\t\tmodel, enc, postprocessor, c.MIN_SUMMARY_TOKENS,\n",
    "\t\tcontext_size, device, c.TEMPERATURE, c.REPETITION_PENALTY, c.TOP_P\n",
    "\t) for enc in encoders\n",
    "] if model_name != \"gpt\" else [\n",
    "\tp.OpenAIPipeline(\n",
    "\t\tmodel, enc, postprocessor, c.SYSTEM_PROMPT\n",
    "\t) for enc in encoders\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = preprocessor(texts)\n",
    "threshold = .5\n",
    "num_segments_found = []\n",
    "for text in processed_texts:\n",
    "\tkeywords = u.get_keywords(text, 20, stop_words, keywords_preprocessor)\n",
    "\tkeywords = \" \".join(keywords)\n",
    "\tkeyword_emb = sent_encoder.encode(keywords)\n",
    "\tsegments = text_segmenter(text)\n",
    "\tsegment_embs = sent_encoder.encode(segments)\n",
    "\tscores = segment_embs @ keyword_emb\n",
    "\tnum_segments = (scores > threshold).sum()\n",
    "\tnum_segments_found.append(num_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(num_segments_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{c.BASE_DIR}/pegasus-govreport.pkl\", \"rb\") as fp:\n",
    "\tresults = pickle.load(fp)\n",
    "scores = results[\"scores\"]\n",
    "sort1, sort2, sort3 = results[\"sort1\"], results[\"sort2\"], results[\"sort3\"]\n",
    "gen_summaries = results[\"gen_summaries\"]\n",
    "scores[0][sort1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "problem_text = results[\"texts\"][sort1[ind]]\n",
    "print(gen_summaries[sort1[ind]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{c.BASE_DIR}/bart-bigpatent-times.json\") as fp:\n",
    "\tresults = json.load(fp)\n",
    "times = np.array(results[\"encoder_times\"])[1:]\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\n",
    "\t\"Truncate\\nMiddle\", \"Document\\nSkimming\",\n",
    "\t\"Skimming w/\\npost-sampling\\nremoval\",\n",
    "\t\"Skimming\\nw/ pre-\\nsampling\\nremoval\", \"Summarization\\nw/ Keyword\\nExtraction\"\n",
    "], times, color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "\t[1, 2],\n",
    "\t[3, 4],\n",
    "\t[5, 6]\n",
    "])\n",
    "b = np.array([1, 1])\n",
    "\n",
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter(torch.nn.Parameter):\n",
    "\n",
    "\tdef __init__(self, val) -> None:\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.val = float(val)\n",
    "\t\tself.param = torch.nn.Parameter(torch.tensor(self.val))\n",
    "\n",
    "\t# def __add__(self, other):\n",
    "\t# \treturn self.param + other\n",
    "\t\n",
    "\t# def __radd__(self, other):\n",
    "\t# \treturn self.param + other\n",
    "\t\n",
    "\t# def __mul__(self, other):\n",
    "\t# \treturn self.param * other\n",
    "\t\n",
    "\t# def __rmul__(self, other):\n",
    "\t# \treturn self.param * other\n",
    "\n",
    "class Custom(torch.nn.Module):\n",
    "\n",
    "\tdef __init__(self):\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.c = 5\n",
    "\t\tself.param = Parameter(2)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn x * self.param + self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCustom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model(\u001b[38;5;241m2.\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 27\u001b[0m, in \u001b[0;36mCustom.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam \u001b[38;5;241m=\u001b[39m \u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Workspace/Environments/uccs-reu/lib/python3.12/site-packages/torch/nn/parameter.py:43\u001b[0m, in \u001b[0;36mParameter.__new__\u001b[0;34m(cls, data, requires_grad)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor\u001b[38;5;241m.\u001b[39m_make_subclass(\u001b[38;5;28mcls\u001b[39m, data, requires_grad)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Path for custom tensors: set a flag on the instance to indicate parameter-ness.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mrequires_grad_(requires_grad)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating a Parameter from an instance of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires that detach() returns an instance of the same type, but return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(t)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was found instead. To use the type as a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter, please correct the detach() semantics defined by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mits __torch_dispatch__() implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "model = Custom()\n",
    "\n",
    "model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "\tprint(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uccs-reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

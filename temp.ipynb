{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import getsizeof\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import inspect\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import (\n",
    "\tBartTokenizer, BartForConditionalGeneration,\n",
    "\tT5Tokenizer, T5ForConditionalGeneration,\n",
    "\tGPT2TokenizerFast\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "from utils.helpers import *\n",
    "from utils.encoders import *\n",
    "from utils.pipelines import *\n",
    "from utils.trainer_utils import *\n",
    "from utils.evaluator_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/Users/naman/Workspace/Data/UCCS-REU\"\n",
    "data_dir = \"/home/nchibbar/Data\"\n",
    "\n",
    "crs_files = os.listdir(crs_dir := f\"{data_dir}/GovReport/crs\")\n",
    "gao_files = os.listdir(gao_dir := f\"{data_dir}/GovReport/gao\")\n",
    "\n",
    "print(f\"crs files: {len(crs_files)}, gao files: {len(gao_files)}\")\n",
    "\n",
    "crs_out = f\"{data_dir}/GovReport/crs-processed\"\n",
    "gao_out = f\"{data_dir}/GovReport/gao-processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 512\n",
    "\n",
    "# Sentence transformer\n",
    "sent_dir = f\"{data_dir}/Models/Sent-Transformer\"\n",
    "sent_encoder = SentenceTransformer(sent_dir)\n",
    "\n",
    "# BART\n",
    "bart_dir = f\"{data_dir}/Models/BART\"\n",
    "bart_fine_tuned = f\"{data_dir}/Models/BART-GovReport-SentenceSampler\"\n",
    "tokenizer = BartTokenizer.from_pretrained(bart_dir)\n",
    "model = BartForConditionalGeneration.from_pretrained(bart_fine_tuned)\n",
    "context_size = model.config.max_position_embeddings\n",
    "\n",
    "# T5\n",
    "# t5_dir = f\"{data_dir}/Models/T5\"\n",
    "# tokenizer = T5Tokenizer.from_pretrained(t5_dir)\n",
    "# model = T5ForConditionalGeneration.from_pretrained(t5_dir)\n",
    "# context_size = model.config.n_positions\n",
    "\n",
    "# GPT 3.5 turbo tokenizer\n",
    "gpt_dir = f\"{data_dir}/Models/GPT-3.5-turbo-tokenizer\"\n",
    "gpt_tokenizer = GPT2TokenizerFast.from_pretrained(gpt_dir)\n",
    "\n",
    "context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextProcessor(preprocessing=True)\n",
    "postprocessor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GovReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subsections(sections):\n",
    "\ttext = \"\"\n",
    "\tfor sec in sections:\n",
    "\t\tsec_text = \"\\n\\n\".join(sec[\"paragraphs\"])\n",
    "\t\tif sec[\"section_title\"]:\n",
    "\t\t\tsec_text = f\"Section {sec[\"section_title\"]}:\\n\\n{sec_text}\"\n",
    "\t\ttext = f\"{text}\\n\\n{sec_text}\" if text else sec_text\n",
    "\t\tif sec[\"subsections\"]:\n",
    "\t\t\tsub_text = combine_subsections(sec[\"subsections\"])\n",
    "\t\t\ttext = f\"{text}\\n\\n{sub_text}\" if text else sub_text\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in crs_files:\n",
    "\twith open(f\"{crs_dir}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\ttext = combine_subsections([data[\"reports\"]])\n",
    "\ttext = preprocessor.process(text)\n",
    "\tsummary = \"\\n\".join(data[\"summary\"])\n",
    "\tsummary = preprocessor.process(summary)\n",
    "\twith open(f\"{crs_out}/{file}\", \"w\") as fp:\n",
    "\t\tjson.dump({\n",
    "\t\t\t\"text\": text,\n",
    "\t\t\t\"summary\": summary\n",
    "\t\t}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in gao_files:\n",
    "\twith open(f\"{gao_dir}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\ttext = combine_subsections(data[\"report\"])\n",
    "\ttext = preprocessor.process(text)\n",
    "\tprint(data[\"highlight\"])\n",
    "\tsummary = \"\\n\".join(data[\"highlight\"])\n",
    "\tsummary = preprocessor.preprocess(summary)\n",
    "\twith open(f\"{gao_out}/{file}\", \"w\") as fp:\n",
    "\t\tjson.dump({\n",
    "\t\t\t\"text\": text,\n",
    "\t\t\t\"summary\": summary\n",
    "\t\t}, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform([data[\"text\"]])\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = 4\n",
    "lda = LatentDirichletAllocation(n_components=topics)\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_dist = lda.transform(dtm)\n",
    "print(topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words):\n",
    "\tfor topic_idx, topic in enumerate(model.components_):\n",
    "\t\tprint(f\"Topic {topic_idx}:\")\n",
    "\t\tprint(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words = 10\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "display_topics(lda, feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, summaries = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max 73_791\n",
    "min_words_text = 70_000\n",
    "for file in crs_files:\n",
    "\twith open(f\"{crs_out}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\tif count_words(data[\"text\"]) >= min_words_text:\n",
    "\t\tbreak\n",
    "texts.append(data[\"text\"])\n",
    "summaries.append(data[\"summary\"])\n",
    "\n",
    "count_words(data[\"text\"]), count_words(data[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, summaries = [], []\n",
    "for file in crs_files:\n",
    "\twith open(f\"{crs_out}/{file}\") as fp:\n",
    "\t\tdata = json.load(fp)\n",
    "\ttexts.append(data[\"text\"])\n",
    "\tsummaries.append(data[\"summary\"])\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 4096\n",
    "head_size = .5\n",
    "threshold = .7\n",
    "seed = 69\n",
    "device = get_device()\n",
    "# device = \"cpu\"\n",
    "\n",
    "encoder = RemoveRedundancy(\n",
    "\tgpt_tokenizer, max_tokens, nltk.sent_tokenize, sent_encoder,\n",
    "\tpreprocessor, False, device=device, seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = \"gpt-3.5-turbo\"\n",
    "system_prompt = \"You summarize very long texts, given some of its sentences. You extract key information and ideas from the sentences to generate a detailed, concise, and coherent summary with more than 500 words. Do not refer to the source text in any way.\"\n",
    "\n",
    "openai_pipeline = OpenAIPipeline(\n",
    "\topenai_model, encoder, system_prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "\n",
    "\tdef __init__(\n",
    "\t\tself, pipelines, rouge_metrics: list[str]|None=None,\n",
    "\t\trougen_max_n: int=2, rougew_weight_factor: int=1.2,\n",
    "\t\tdevice: str|torch.device|None=None\n",
    "\t) -> None:\n",
    "\t\t# Initialize pipelines\n",
    "\t\tpipelines = self.pipelines = pipelines if \\\n",
    "\t\t\tisinstance(pipelines, list) else [pipelines]\n",
    "\t\tself.num_pipelines = len(pipelines)\n",
    "\n",
    "\t\t# Initialize BERT scorer\n",
    "\t\tself.bert_scorer = BERTScorer(lang=\"en\", device=device)\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\t# Initialise ROUGE scorer\n",
    "\t\tif rouge_metrics is None:\n",
    "\t\t\trouge_metrics = [\"rouge-n\", \"rouge-l\", \"rouge-w\"]\n",
    "\t\tself.rouge_scorer = Rouge(\n",
    "\t\t\tmetrics=rouge_metrics, max_n=rougen_max_n, limit_length=False,\n",
    "\t\t\tweight_factor=rougew_weight_factor\n",
    "\t\t)\n",
    "\t\tif \"rouge-n\" in rouge_metrics:\n",
    "\t\t\trouge_metrics.remove(\"rouge-n\")\n",
    "\t\t\tself.rouge_metrics = [\n",
    "\t\t\t\tf\"rouge-{i+1}\" for i in range(rougen_max_n)\n",
    "\t\t\t]\n",
    "\t\t\tself.rouge_metrics.extend(rouge_metrics)\n",
    "\t\telse:\n",
    "\t\t\tself.rouge_metrics = rouge_metrics\n",
    "\t\tself.rougen_max_n = rougen_max_n\n",
    "\t\tself.rougew_weight_factor = rougew_weight_factor\n",
    "\n",
    "\t\tself.generated_summaries = None\n",
    "\n",
    "\tdef __call__(\n",
    "\t\tself, texts: str|list[str], summaries: str|list[str],\n",
    "\t\tbatch_size: int|None=None, num_workers: int|None=None\n",
    "\t) -> dict:\n",
    "\t\ttime_taken = self.generate_summaries(texts, batch_size, num_workers)\n",
    "\t\tprint(f\"Time taken to generate summaries: {time_taken}\")\n",
    "\t\tbert_score = self.get_bert_score(summaries)\n",
    "\t\trouge_score = self.get_rouge_score(summaries)\n",
    "\t\tscores = {\n",
    "\t\t\t\"time-taken\": time_taken,\n",
    "\t\t\t\"bert-scores\": bert_score,\n",
    "\t\t\t\"rouge-scores\": rouge_score\n",
    "\t\t}\n",
    "\t\treturn scores\n",
    "\t\n",
    "\tdef generate_summaries(\n",
    "\t\tself, texts: str|list[str], batch_size: int|None=None,\n",
    "\t\tnum_workers: int|None=None\n",
    "\t) -> list[int]:\n",
    "\t\tif isinstance(texts, str):\n",
    "\t\t\ttexts = [texts]\n",
    "\t\tgenerated_summaries = self.generated_summaries = []\n",
    "\t\ttime_taken = []\n",
    "\t\tinputs = [\n",
    "\t\t\t(texts, i, batch_size) for i in range(self.num_pipelines)\n",
    "\t\t]\n",
    "\t\tif num_workers is not None and num_workers > 1:\n",
    "\t\t\twith ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "\t\t\t\tresults = executor.map(self._generate_summaries, inputs)\n",
    "\t\telse:\n",
    "\t\t\tresults = map(self._generate_summaries, inputs)\n",
    "\t\tfor summary, time in results:\n",
    "\t\t\tgenerated_summaries.extend(summary)\n",
    "\t\t\ttime_taken.append(time)\n",
    "\t\treturn time_taken\n",
    "\t\n",
    "\t# P, R, F\n",
    "\tdef get_bert_score(\n",
    "\t\tself, summaries: str|list[str]\n",
    "\t) -> list[torch.Tensor]:\n",
    "\t\tgenerated_summaries = self.generated_summaries\n",
    "\t\tassert generated_summaries is not None, \"Summaries not generated\"\n",
    "\t\tnum_pipelines = self.num_pipelines\n",
    "\t\tsummaries = num_pipelines * summaries\n",
    "\t\tmetrics = self.bert_scorer.score(generated_summaries, summaries)\n",
    "\t\tmetrics = np.array([\n",
    "\t\t\tmetric.reshape((num_pipelines, -1)).mean(dim=1)\n",
    "\t\t\tfor metric in metrics\n",
    "\t\t])\n",
    "\t\torder = [2, 0, 1]\n",
    "\t\tmetrics = metrics.T[:, order].tolist()\n",
    "\t\treturn metrics\n",
    "\t\n",
    "\t# F, P, R\n",
    "\tdef get_rouge_score(\n",
    "\t\tself, summaries: str|list[str]\n",
    "\t) -> list[dict[str, np.ndarray]]:\n",
    "\t\tgenerated_summaries = self.generated_summaries\n",
    "\t\tassert generated_summaries is not None, \"Summaries not generated\"\n",
    "\t\tnum_generated_summaries = len(generated_summaries)\n",
    "\t\tnum_summaries = len(summaries)\n",
    "\t\tscores = []\n",
    "\t\tfor i in range(0, num_generated_summaries, num_summaries):\n",
    "\t\t\tpipeline_summaries = generated_summaries[i:i+num_summaries]\n",
    "\t\t\tmean_score = {\n",
    "\t\t\t\tmetric: np.array([0., 0, 0])\n",
    "\t\t\t\tfor metric in self.rouge_metrics\n",
    "\t\t\t}\n",
    "\t\t\tfor cand, ref in zip(pipeline_summaries, summaries):\n",
    "\t\t\t\tscore = self.rouge_scorer.get_scores(cand, ref)\n",
    "\t\t\t\tfor metric, values in score.items():\n",
    "\t\t\t\t\tmean_score[metric] += list(values.values())\n",
    "\t\t\tfor metric, values in mean_score.items():\n",
    "\t\t\t\tmean_score[metric] = (values / num_summaries).tolist()\n",
    "\t\t\tscores.append(mean_score)\n",
    "\t\treturn scores\n",
    "\t\n",
    "\tdef _generate_summaries(self, args):\n",
    "\t\ttexts, ind, batch_size = args\n",
    "\t\tpipeline = self.pipelines[ind]\n",
    "\t\tstart = perf_counter()\n",
    "\t\tsummaries = pipeline(texts, batch_size)\n",
    "\t\ttime_taken = (perf_counter() - start)\n",
    "\t\tprint(f\"Generated summary for pipeline {ind+1} in {time_taken}s\")\n",
    "\t\treturn summaries, time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(openai_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator(texts, summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_pipeline.response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer.decode(encoder.encode(texts[0], max_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uccs-reu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

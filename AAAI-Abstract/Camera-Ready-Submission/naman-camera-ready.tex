%File: formatting-instructions-latex-2025.tex
%release 2025.0
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
    basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
    numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
    aboveskip=0pt,belowskip=0pt,%
    showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

% Manually added packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{algpseudocode}

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Automatic Summarization of Long Documents (Student Abstract)}

\author{
%Authors
% All authors must be in the same font size and format.
  Naman Chhibbar\textsuperscript{\rm 1},
  Jugal Kalita\textsuperscript{\rm 2}
}

\affiliations{
  %Afiliations
  \textsuperscript{\rm 1}Indian Institute of Technology, Hyderabad \\
  \textsuperscript{\rm 2}University of Colorado, Colorado Springs \\
  % email address must be in roman text type, not monospace or sans serif
  naman.iith@gmail.com, jkalita@uccs.edu
}


\begin{document}
\maketitle

\begin{abstract}
A vast amount of text is added to the internet daily, making utilization and interpretation of textual data complex and cumbersome.
As a result, automatic text summarization is crucial for extracting relevant information, saving precious time.
Although many transformer models excel in summarization, they are constrained by their input size, preventing them from processing texts longer than their context size.
This study introduces several novel algorithms that allow any LLM to efficiently overcome its input size limitation, effectively utilizing its full potential without any architectural modifications.
We test our algorithms on texts with more than 70,000 words, and our experiments show a significant increase in BERTScore with competitive ROUGE scores.
\end{abstract}


\section{Introduction}

Due to the ever-increasing amount of online textual data, document summarization has become crucial for the efficient and accurate extraction of relevant information.
Large Language Models (LLMs) based on transformers have shown outstanding abilities in many NLP tasks, including document summarization.
Recent developments have demonstrated remarkable improvements in the relevancy and coherence of summaries generated by such LLMs.

However, long document summarization, which involves removing redundancies and makes reading long texts concise and efficient, remains a major challenge.
One of the significant limitations in the transformer architecture is limited context size, stemming from the quadratic memory and computational complexity of the attention mechanism \cite{du2023improving}.
This constraint hinders extracting relevant information from extensive texts where summarization is valuable to overcome the time, effort, and interpretative issues posed by complex and large documents.

We experiment with novel approaches to address the input size limitations of transformers.
The methods introduced do not include any architectural modifications to the model used for summarization and can be incorporated into any existing summarization pipeline.
We believe that these methods can effectively utilize the full potential of any existing LLM by capturing information from crucial aspects of the document.
Although our experiments focus on summarization, we hypothesize that our methods can be applied to NLP tasks that require processing long texts.


\section{Problem Statement}

Our goal is to distill a long document such that it fits within the context size of the model while retaining important information.
In our experiments, we use documents with lengths up to \textbf{seventeen times} the context size of the model and aim to reduce the summary length to about 400 words or less, preserving maximal information and coherence.


\section{Methodology}

In this section, we introduce the three algorithms used in our experiments.
Two of the three algorithms start by segmenting the text into smaller, contiguous, and exhaustive parts.
This is done by using a sentence tokenizer to separate sentences and then grouping them to form the segments.

\subsection{Central Truncation}

In this method, we truncate the text from the middle; that is, we keep parts from the start and the end of the document.
This time-efficient method is an adaptation of \citet{worsham-kalita-2018-genre} and \citet{sun2019fine}, both of which pertain to long text classification.
We introduce a new hyperparameter to control the fraction of the text to be taken from the head.

\subsection{Document Skimming}

Our second method is inspired by the speed reading strategy called skimming \cite{dhillon2020effect}, which involves skipping over less important parts of the text for efficiency.
This method starts by segmenting the document into smaller segments and then uniformly samples the segments, meaning each segment has an equal probability of being selected.
This ensures that the model is exposed to all parts of the document while preserving efficiency.
We also experiment with removing redundant segments before and after sampling to prevent the model from repeating itself.
While removing redundant segments before sampling requires processing the whole document, it ensures better utilization of the context size of the model.
Whereas removing redundant segments after sampling is computationally efficient, it may not use the context size to its full extent.
To alleviate this, we over-sample the segments beforehand.

\subsection{Summarization with Keyword Extraction}

The last method is based on extracting keywords from the text to help choose the segments intelligently.
We use LDA \cite{blei2003latent} with a single topic to extract topic words (keywords) from the text.
These keywords are concatenated with space as a delimiter to form a single sentence.
This sentence is compared against the segments using a sentence transformer using cosine similarity to gain scores for each segment.
Segments with the highest scores are selected for summarization.


\section{Experiments}

We conduct our experiments on the GovReport \cite{huang-etal-2021-efficient} and the BigPatent \cite{sharma-etal-2019-bigpatent} datasets with maximum word counts of 73,815 and 71,027, respectively.
We use ROUGE-1 (R-1), ROUGE-2 (R-2), and ROUGE-L (R-L) scores \cite{lin-2004-rouge} and BERTScore \cite{zhang2019bertscore} to evaluate the generated summaries.
Our baselines include: Unlimiformer \cite{bertsch2023unlimiformer} in which the decoder only attends to the tokens picked by k-Nearest-Neighbour tokens in the input, Hepos \cite{huang-etal-2021-efficient} in which the decoder only attends to $n/s_h$ tokens in the input, where $n$ is the input length and $s_h$ is the number of decoder heads, PEGASUS-X \cite{phang2022investigating} with staggered block-local attention, LLaMA-7B \cite{chen2022long} with positional interpolation, and BigBird-Pegasus \cite{zaheer2020big}.
The models we used for summarization are BART \cite{lewis-etal-2020-bart}, LongT5 \cite{guo2021longt5}, and GPT-3.5 Turbo \cite{brown2020language}.
Context sizes of the models are provided in parentheses in the tables.

We could not obtain BERTScores for some baselines due to code unavailability or computational limitations.

\begin{table}[!ht]
  \centering
  \scriptsize

  \begin{tabular}{c c c c c}
    \hline
    Model & R-1 & R-2 & R-L & BERTScore \\
    \hline
    BART /w Unlimiformer (1,024) & 53.4 & 22.5 & 22.5 & 66.0 \\
    PRIMERA w/ & 56.5 & 24.8 & 26.3 & 67.7 \\
    Unlimiformer (4,096) & & & & \\
    Hepos (10,240) & 51.34 & 19.09 & \textbf{48.73} & - \\
    PEGASUS-X /w Staggered & 60.3 & \textbf{30.0} & 31.5 & - \\
    Block-Local Attention (16k) & & & & \\
    LLaMA-7B /w Positional & 60.0 & 28.0 & 29.5 & - \\
    Interpolation (15k) & & & & \\
    \hline
    Summarization /w Extraction & \textbf{61.99} & 18.52 & 38.46 & \textbf{86.20} \\
    /w GPT-3.5 Turbo (4,096) & & & & \\
    Central truncation & 46.20 & 4.38 & 38.27 & 82.19 \\
    /w LongT5 (4,096) & & & & \\
    Skimming /w post-sampling & 46.76 & 4.56 & 39.61 & 81.96 \\
    removal /w LongT5 (4,096) & & & & \\
    \hline
  \end{tabular}

  \caption{
    Automatic evaluation on GovReport dataset.
    The best metric in each category is highlighted in \textbf{bold}.
  }
  \label{tab:govreport}
\end{table}

\begin{table}[!t]
  \centering
  \scriptsize

  \begin{tabular}{c c c c c}
    \hline
    Model & R-1 & R-2 & R-L & BERTScore \\
    \hline
    BigBird-Pegasus (16k) & \textbf{60.64} & \textbf{42.46} & \textbf{50.01} & - \\
    \hline
    Skimming w/ pre-sampling & 27.40 & 3.31 & 21.25 & \textbf{82.62} \\
    removal w/ GPT-3.5 Turbo (4,096) & & & & \\
    Central truncation & 27.77 & 3.09 & 20.56 & 82.57 \\
    w/ GPT-3.5 Turbo (4,096) & & & & \\
    Skimming w/ post-sampling & 26.16 & 2.13 & 20.21 & 82.40 \\
    removal w/ GPT-3.5 Turbo (4,096) & & & & \\
    \hline
  \end{tabular}

  \caption{
    Automatic evaluation on BigPatent dataset.
    The best metric in each category is highlighted in \textbf{bold}.
  }
  \label{tab:bigpatent}
\end{table}


\section{Future Work}

We find that segmentation is a crucial step in the pipeline and can influence the output summary significantly; ensuring the uniformity of the length of the segments while preserving coherence is essential.
We encourage future work to experiment with different segmenters.
Future work can also focus on extending the "Summarization with Keyword Extraction" method.
One possibility is experimenting with different ways of using keywords and extraction algorithms.


\section{Conclusion}

Our experiments show that "Document Skimming" with post-sampling removal (of redundant segments) performs well and is efficient.
The "Central Truncation" method also shows good results, which shows that simple methods can also be effective in long document summarization.
"Document Skimming" with pre-sampling removal and "Summarization with Keyword Extraction" achieve the best results but are computationally expensive.

Our experiments show a significant increase in BERTScore compared to Unlimiformer.
This shows that our pipelines can efficiently utilize details in long texts.
Even though our ROUGE-2 scores are lower than the baselines, ROUGE-1 and ROUGE-L scores are competitive.
Since BERTScore is better at capturing semantic similarity, we highlight the use of BERTScore compared to ROUGE scores.
Hence, we hypothesize that our pipelines generate better summaries even though ROUGE scores are not the highest.
It should also be noted that the models used in our experiments have much smaller context sizes than the baselines, indicating that our algorithms have a greater potential if used with larger models.


\section*{Acknowledgement}
  
All work herein reported is supported by the Nation Science Foundation under Grant No. 2349452.
Any opinion, finding, or conclusion in this study is that of the authors and does not necessarily reflect the views of the National Science Foundation.


\bibliography{anthology.bib}

\end{document}

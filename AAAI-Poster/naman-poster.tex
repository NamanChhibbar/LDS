\documentclass[20pt]{beamer}
\usepackage[size=custom, height=80, width=100, scale=1.5]{beamerposter}
\usepackage{graphicx}
\usepackage{multicol}
% \usepackage{amsmath}
% \usepackage{amssymb}
\usepackage[numbers]{natbib}
\usepackage{soul}

\setulcolor{black}
\newcommand{\heading}[1]{\ul{\textbf{#1}} \\}
\bibliographystyle{plainnat}

% Theme settings
% \usetheme{ConfPoster}
% \usecolortheme{dolphin}  % You can experiment with different color themes

% Title and Author Information
\title{Automatic Summarization of Long Documents}
\author{
  Naman Chhibbar\textsuperscript{\rm 1},
  Jugal Kalita\textsuperscript{\rm 2}
}
\institute{
  \textsuperscript{\rm 1}Indian Institute of Technology, Hyderabad \\
  \textsuperscript{\rm 2}University of Colorado, Colorado Springs \\
  \texttt{naman.iith@gmail.com, jkalita@uccs.edu}
}

\begin{document}
\begin{frame}[t]

% Title Block
\begin{columns}[t]
  \column{.2\textwidth}
    \begin{figure}[!h]
      \centering
      \includegraphics[width=.4\textwidth]{images/iith.png}
      \hspace{1cm}
      \includegraphics[width=.4\textwidth]{images/uccs.png}
    \end{figure}
  \column{.8\textwidth}
    \vspace{1cm}
    \begin{minipage}{\columnwidth}
      \centering
      \huge\textbf\inserttitle \\
      \large\textbf\insertauthor \\
      \large\insertinstitute
    \end{minipage}
\end{columns}
\vspace{1cm}

% Poster Content
\begin{columns}[t]

  \column{.33\textwidth}
  \begin{block}{Introduction}
    The rapid growth of online textual data has made \textbf{document summarization} essential for extracting relevant information efficiently.
    \textbf{Transformer models} have demonstrated remarkable capabilities in this domain, producing coherent and relevant summaries.
    However, \textbf{long document summarization remains a challenge} due to the \textbf{limited context size} of transformers, which stems from quadratic memory and computational complexity of the attention mechanism.
    This constraint makes it difficult to process extensive texts wherein summarization is crucial for reducing reading time and improving comprehension.
    We explore three novel methods to overcome input size limitations in transformers \textbf{without modifying the model architecture}.
    These methods can be integrated into any existing summarization pipelines, maximizing an LLM’s ability to extract key information.
  \end{block}

  \begin{block}{Methodology}
    \heading{Central Truncation}
    In this method, we truncate the text from the middle; that is, we keep parts of the beginning and end of the document.
    This is an extension of the default truncation method used to handle long inputs in transformers.
    We introduce a hyperparameter to control the fraction of the text to be taken from the head.

    \heading{Document Skimming}
    This method first segments the document and then uniformly samples the segments, meaning each segment has an equal probability of being sampled.
    This ensures the model is exposed to all document parts while preserving efficiency.
    We also experiment with removing redundant segments before and after sampling to prevent the model from repeating itself.
    \begin{figure}[!h]
      \centering
      \includegraphics[width=\textwidth]{images/doc-skim.png}
      \caption{Document Skimming illustration. Grey blocks denote tokens in text.}
    \end{figure}
  \end{block}


  \column{.33\textwidth}
  \vspace{.8cm}
  \begin{minipage}{\columnwidth}
    \heading{Summarization with Keyword Extraction}
    This method extracts keywords from the text to help intelligently choose the segments.
    We use Latent Dirichlet allocation (LDA) with a single topic to extract topic words (keywords) from the text.
    These keywords are concatenated with space as a delimiter to form a single sentence.
    This sentence is compared against the segments using a sentence transformer using cosine similarity to gain scores for each segment.
    Segments with the highest scores are selected for summarization.
  \end{minipage}

  \begin{block}{Experiments}

    We conduct our experiments on \textbf{GovReport} and \textbf{BigPatent} datasets with maximum word counts of \textbf{73,815} and \textbf{71,027}, respectively.
    Our methods (below) are separated from the baselines (above) by a horizontal line in both tables.
    The best metric in each table is highlighted in bold.
    Context size of each model is given in parentheses.
    R-1, R-2, and R-L stand for ROUGE-1, ROUGE-2, and ROUGE-L respectively.

    The table below shows the results on GovReport dataset.

    \begin{table}[!ht]
      \centering
      \small

      \begin{tabular}{c c c c c}
        \hline
        Model & R-1 & R-2 & R-L & B-Score \\
        \hline
        BART /w Unlimiformer (1,024) & 53.4 & 22.5 & 22.5 & 66.0 \\
        PRIMERA w/ & 56.5 & 24.8 & 26.3 & 67.7 \\
        Unlimiformer (4,096) & & & & \\
        Hepos (10,240) & 51.34 & 19.09 & \textbf{48.73} & - \\
        PEGASUS-X /w Staggered & 60.3 & \textbf{30.0} & 31.5 & - \\
        Block-Local Attention (16k) & & & & \\
        LLaMA-7B /w Positional & 60.0 & 28.0 & 29.5 & - \\
        Interpolation (15k) & & & & \\
        \hline
        Summarization /w Extraction & \textbf{61.99} & 18.52 & 38.46 & \textbf{86.20} \\
        /w GPT-3.5 Turbo (4,096) & & & & \\
        Central truncation & 46.20 & 4.38 & 38.27 & 82.19 \\
        /w LongT5 (4,096) & & & & \\
        Skimming /w post-sampling & 46.76 & 4.56 & 39.61 & 81.96 \\
        removal /w LongT5 (4,096) & & & & \\
        \hline
      \end{tabular}

      \label{tab:govreport}
    \end{table}

    Below are the results on BigPatent dataset.

    \begin{table}[!t]
      \centering
      \small

      \begin{tabular}{c c c c c}
        \hline
        Model & R-1 & R-2 & R-L & B-Score \\
        \hline
        BigBird-Pegasus (16k) & \textbf{60.64} & \textbf{42.46} & \textbf{50.01} & - \\
        \hline
        Skimming w/ pre-sampling & 27.40 & 3.31 & 21.25 & \textbf{82.62} \\
        removal w/ GPT-3.5 Turbo (4,096) & & & & \\
        Central truncation & 27.77 & 3.09 & 20.56 & 82.57 \\
        w/ GPT-3.5 Turbo (4,096) & & & & \\
        Skimming w/ post-sampling & 26.16 & 2.13 & 20.21 & 82.40 \\
        removal w/ GPT-3.5 Turbo (4,096) & & & & \\
        \hline
      \end{tabular}

      \label{tab:bigpatent}
    \end{table}
  \end{block}


  \column{.33\textwidth}
  \vspace{.8cm}
  \begin{minipage}{\columnwidth}
    The bar chart below depicts the time taken by each method (in milliseconds).
    \begin{figure}[!h]
      \centering
      \includegraphics[width=.8\textwidth]{images/encoder-times.png}
    \end{figure}
  \end{minipage}

  \begin{block}{Conclusion}
    Our experiments demonstrate that “Document Skimming” with post-sampling removal achieves strong performance while remaining efficient, while the “Central Truncation” method also performs well, highlighting the effectiveness of simple approaches in long-document summarization.
    “Document Skimming” with pre-sampling removal and “Summarization with Keyword Extraction” yield the best results but are computationally expensive.
    Our methods show a significant BERTScore improvement over Unlimiformer, indicating better semantic understanding.
    While our ROUGE-2 scores are lower, ROUGE-1 and ROUGE-L remain competitive.
    Given that BERTScore better captures semantic similarity, we emphasize its importance over ROUGE scores.
    Despite using models with much smaller context sizes than the baselines, our methods demonstrate strong potential, especially when scaled to larger models.
  \end{block}

  \begin{block}{Acknowledgments}
    All work herein reported is supported by the National Science Foundation under Grant No. 2349452.
    Any opinion, finding, or conclusion in this study is that of the authors and does not necessarily reflect the views of the National Science Foundation.
  \end{block}
\end{columns}

\end{frame}
\end{document}
